# MULTI-MODAL-VOICE-ASSISTANCE

<b>Team Name</b> : TurningTitans<br>
<b>Team ID </b>  : 0527<br>
<b>Hack Name</b> : Ion-IQ<br>
<b>Theme</b>     : #2<br>
<b>Members</b>   : 4<br>
<table>
  <tr>
    <th>Name</th>
    <th>Email</th>
    <th>Branch & Year</th>
    <th>Phone</th>
  </tr>
   <tr>
    <td>Hariharan.R.B</td>
    <td>hariharan.2023vitstudent.ac.in</td>
    <td>MSc Data Science, 1styear</td>
    <td>9159564077</td>
  <tr>
    <td>Mahalakshmi.A</td>
    <td>mahalakshmi.arasu2023@vitstudent.ac.in</td>
    <td>MSc Data Science, 1styear</td>
    <td>82484 80167</td>
  </tr>
     <tr>
    <td>Sri krishna.V</td>
    <td>sri.krishna2023@vitstudent.ac.in</td>
    <td>MSc Data Science, 1styear</td>
    <td>91766 25759</td>
  </tr>
  <tr>
    <td>Kamalesh.K</td>
    <td>hariharan.2023vitstudent.ac.in</td>
    <td>MSc Data Science, 1styear</td>
    <td>80153 29920</td>
  </tr>
</table>


## Implementation üõ†Ô∏è


**Documentation:**

1. **Introduction:**

   *Introducing the "Multi-Modal Voice Assistant App": a user-friendly tool designed to simplify daily tasks through voice and image interactions. With this app, users can communicate with the assistant by typing or speaking commands, making it accessible to all.*

    *The app offers a range of features, including image analysis, video summarization, YouTube video transcription, PDF reading, and health advice. For instance, users can upload images to identify objects or upload videos for quick summaries. Additionally, they can transcribe YouTube videos or ask questions about PDF documents.*

   *One notable feature is the Health Advisor, where users can upload images of food items to receive detailed nutritional information, including calorie counts and dietary recommendations.*

   * With its intuitive interface and advanced AI capabilities, the Multi-Modal Voice Assistant App aims to streamline tasks and provide valuable assistance to users in various domains, from content analysis to health monitoring.*

2. **Libraries Used:**
   
   - **Streamlit:** *A Python library for building interactive web applications with simple Python scripts, facilitating seamless user interaction.*
   - **Requests:** *A library for making HTTP requests, enabling communication with external APIs for data retrieval.*
   - **Google Generative AI:** *A suite of AI models and tools for generating text and image content, used for analyzing food images and providing nutritional insights.*
   - **SpeechRecognition:** *A library for performing speech recognition, allowing users to interact with the assistant through voice commands.*
   - **Pyttsx3:** *A text-to-speech conversion library used to generate audible responses from text inputs, enhancing user interaction.*
   - **MoviePy:** *A Python library for video editing, utilized here for extracting audio from uploaded videos for analysis.*
   - **PyPDF2:** *A library for reading PDF files, used for extracting text content from uploaded documents.*
   - **langchain:** *A library for text analysis and processing, utilized for breaking down large text documents and generating embeddings.*
   - **PIL (Python Imaging Library):** *A library for opening, manipulating, and saving various image file formats, employed for image processing.*
   - **YouTube Transcript API:** *An API for retrieving transcripts of YouTube videos, enabling analysis of video content.*
   - **dotenv:** *A library for loading environment variables from a .env file into the application's environment.*
   
3. **Features:**

   - **Multimodal Input Processing:** *The assistant accepts inputs through text, voice, and image modalities, providing users with flexibility and convenience in interaction.*
   - **Nutritional Analysis:** *Leveraging Google Generative AI, the assistant analyzes uploaded food images to determine nutritional content and provide detailed calorie breakdowns.*
   - **Personalized Recommendations:** *Based on the nutritional analysis, the assistant offers personalized recommendations and insights to users, promoting healthy eating habits.*
   - **Voice Interaction:** *Utilizing speech recognition and text-to-speech conversion, the assistant supports voice-based interaction, enhancing accessibility and user experience.*
   - **Document and Video Analysis:** *The assistant can analyze text documents and video transcripts, extracting relevant information and providing summarized insights.*
   
4. **User Interface:**

   - *The application interface, built using Streamlit, offers a user-friendly environment for interacting with the Multimodal Health Assistant.*
   - *Users can input queries, upload food images, or provide video links through the intuitive interface.*
   - *Real-time feedback and responses are displayed to users, ensuring seamless communication and engagement.*
   
5. **Conclusion:**

   The Multimodal Voice Assistant project represents a significant advancement in leveraging technology. By integrating multimodal input processing, AI-driven analysis, and personalized recommendations.
